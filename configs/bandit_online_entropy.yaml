# Online training configuration for bandit environment
env: "bandit"
envs: 2000
hists: 1
samples: 1
H: 100
dim: 5
var: 0.3
cov: 0.0

# Model configuration
embd: 32
head: 4
layer: 4
lr: 0.001
dropout: 0
shuffle: true

# Online training configuration
online_training: true
n_epoch: 100
seed: 1


# Entropy penalty coefficient (beta) scheduling
# Options: 'linear', 'stepped', 'linear_interpolate', 'constant'

# For linear: Loss = CE - beta * Entropy, beta decreases from confidence_start to 0
confidence_type: linear_interpolate
confidence_start: 0.3  # Starting beta value (default: 0.1)

# For stepped: Loss = CE - beta * Entropy, beta decreases from confidence_start to 0 at max_position, then stays at 0
# confidence_type: stepped
# confidence_start: 0.1
# max_position: 40  # Position where beta reaches 0 (default: 40)

# For linear_interpolate: Loss = (1-beta) * CE - beta * Entropy, beta decreases from confidence_start to 0
# confidence_type: linear_interpolate
# confidence_start: 0.1

# For constant: beta stays constant
# confidence_type: constant
# confidence_value: 0.1

